{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261b06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.96  Python-3.11.3 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Setup complete  (12 CPUs, 15.9 GB RAM, 176.7/237.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a7b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c61f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.111 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.96  Python-3.11.3 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=web-min-project-akhir.v3i.yolov8\\data.yaml, epochs=100, patience=5, batch=5, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.Detect                [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005078125), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\MyProject\\YOLOv8\\datasets\\web-min-project-akhir.v3i.yolov8\\train\\labels.cache... 373 images, 0 backg\u001b[0m\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 283, len(boxes) = 6500. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\MyProject\\YOLOv8\\datasets\\web-min-project-akhir.v3i.yolov8\\valid\\labels.cache... 47 images, 0 backgrou\u001b[0m\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 30, len(boxes) = 747. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 5 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100     0.954G      2.071      2.297       1.65         50        640: 100%|██████████| 75/75 [00:19<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.206      0.244      0.132     0.0662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100     0.946G      2.029      1.824      1.693        147        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.265      0.449      0.284      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100     0.954G       2.06      1.821      1.725         54        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.332      0.443      0.303      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100     0.975G      2.006      1.773      1.721         79        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.539      0.345      0.364      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      0.91G      1.927      1.575      1.627         46        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.368      0.389      0.333      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100     0.944G      1.912      1.567      1.624         74        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.717      0.549      0.595      0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100     0.893G      1.864      1.492      1.604         61        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.606      0.556      0.561       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      0.96G      1.874      1.474      1.587         84        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.763      0.583      0.658      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      1.02G      1.812      1.363      1.536         81        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.747       0.62      0.652      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100     0.881G       1.82      1.369      1.554        117        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747        0.8      0.632      0.705      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100         1G      1.802      1.346      1.556         74        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.825      0.628      0.731      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100     0.921G        1.9      1.439      1.608         51        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.768      0.581      0.674      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100     0.895G      1.787      1.313      1.534         47        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.824      0.518      0.628      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100     0.916G      1.745      1.267      1.507         75        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.771      0.578      0.695      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100     0.923G      1.734       1.26      1.489        117        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.801      0.619       0.72      0.389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ConfusionMatrix plot failure: Invalid format specifier '%d' for object of type 'float'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100         1G      1.691      1.225      1.464        192        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747       0.81       0.61      0.708      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100     0.977G      1.711      1.231      1.493         70        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.789      0.618        0.7      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      1.03G      1.695      1.259      1.488         69        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.811      0.631      0.746      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100     0.916G      1.671      1.172      1.456         98        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.828      0.638      0.729      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      1.02G      1.682      1.211      1.488         91        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747       0.78      0.659      0.743      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      1.05G      1.696      1.212      1.475         38        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.813      0.679      0.769      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      1.03G      1.658      1.171      1.444         44        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.817      0.671      0.761      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      1.02G      1.673      1.171       1.46        132        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<0\n",
      "                   all         47        747      0.847      0.652      0.761      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      1.08G      1.637      1.117       1.43         49        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.837      0.659      0.775      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100     0.937G      1.619      1.135      1.435         73        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747       0.84      0.636       0.76      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100     0.921G      1.659       1.14      1.462         70        640: 100%|██████████| 75/75 [00:18<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.813      0.677      0.768      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      1.02G      1.626      1.112      1.423         65        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.857       0.66      0.782      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      0.96G      1.606      1.122      1.425         64        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.829      0.709      0.795      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      1.01G      1.607      1.077      1.404         54        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.792      0.675       0.77      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      1.05G      1.635      1.122      1.425         90        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.859      0.677      0.792      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100     0.954G      1.629      1.108       1.43        146        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.773      0.673       0.76      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100     0.925G      1.638      1.108      1.428        159        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.801      0.736      0.799      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100     0.891G      1.579      1.053      1.403         88        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<0\n",
      "                   all         47        747      0.791       0.73      0.816      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100     0.958G      1.615      1.093      1.421         75        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.799      0.697      0.787      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100     0.956G      1.598      1.085      1.409         64        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.782      0.672      0.775      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100     0.925G      1.576      1.079      1.415         73        640: 100%|██████████| 75/75 [00:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747       0.76      0.732      0.757      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100     0.996G      1.568      1.079       1.43         66        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<0\n",
      "                   all         47        747      0.821      0.721      0.803      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100     0.925G      1.584      1.069       1.41         93        640: 100%|██████████| 75/75 [00:17<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.851      0.704      0.803      0.459\n",
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 33, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ConfusionMatrix plot failure: Invalid format specifier '%d' for object of type 'float'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "38 epochs completed in 0.208 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.96  Python-3.11.3 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<0\n",
      "                   all         47        747      0.793       0.73      0.816       0.46\n",
      "                   car         47        282      0.843      0.809      0.887      0.544\n",
      "             crosswalk         47        113      0.742       0.77      0.835      0.514\n",
      "            motorcycle         47        352      0.795      0.611      0.727      0.321\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ConfusionMatrix plot failure: Invalid format specifier '%d' for object of type 'float'\n"
     ]
    }
   ],
   "source": [
    "model.train(data='web-min-project-akhir.v3i.yolov8\\data.yaml',epochs=100,batch=5,imgsz=640,patience=5,optimizer='Adam',device=0,pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436a2889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.96  Python-3.11.3 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\MyProject\\YOLOv8\\datasets\\web-min-project-akhir.v3i.yolov8\\valid\\labels.cache... 47 images, 0 backgrou\u001b[0m\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 30, len(boxes) = 747. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all         47        747      0.795      0.726      0.816      0.461\n",
      "                   car         47        282      0.844      0.804      0.887      0.544\n",
      "             crosswalk         47        113      0.741       0.77      0.834      0.517\n",
      "            motorcycle         47        352      0.801      0.605      0.727      0.322\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 0.0ms loss, 7.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ConfusionMatrix plot failure: Invalid format specifier '%d' for object of type 'float'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x0000018AE954B750>\n",
       "fitness: 0.4964071060089821\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.54364,     0.51693,     0.32214])\n",
       "names: {0: 'car', 1: 'crosswalk', 2: 'motorcycle'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.795112482762673, 'metrics/recall(B)': 0.726259097314457, 'metrics/mAP50(B)': 0.8159508542165032, 'metrics/mAP50-95(B)': 0.46090224509703526, 'fitness': 0.4964071060089821}\n",
       "save_dir: WindowsPath('runs/detect/val4')\n",
       "speed: {'preprocess': 1.2849848321143618, 'inference': 14.296602695546252, 'loss': 0.0, 'postprocess': 7.429046833768804}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2aa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + 0.25*(w-x))\n",
    "            cy = (y + 0.75*(h-y))\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 35:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "#                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84da5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3f1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['car','crosswalk','motorcycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57895998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=Tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf49724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9eec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2=cv2.imread('Desktop Screenshot 2023.05.31 - 17.23.45.06.png')\n",
    "frame2=cv2.resize(frame2,(1920,1080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23865ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 crosswalk, 3 motorcycles, 40.2ms\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(frame2)\n",
    "a=result[0].boxes.boxes.cpu().numpy()\n",
    "px = pd.DataFrame(a).astype('float')\n",
    "list_=[]\n",
    "for index,row in px.iterrows():\n",
    "    x1=int(row[0])\n",
    "    y1=int(row[1])\n",
    "    x2=int(row[2])\n",
    "    y2=int(row[3])\n",
    "    d=int(row[5])\n",
    "    c=class_list[d]\n",
    "    if d==0 or d==2:\n",
    "        list_.append([x1,y1,x2,y2])\n",
    "bbox_id=tracker.update(list_)\n",
    "for bbox in bbox_id:\n",
    "    x3,y3,x4,y4,id=bbox\n",
    "    cx=int(x3+0.25*(x4-x3))\n",
    "    cy=int(y3+0.75*(y4-y3))\n",
    "    cv2.circle(frame2,(cx,cy),4,(0,0,255),-1)\n",
    "    cv2.putText(frame2,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "cv2.imshow(\"RGB\",frame2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0007e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
